{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "from datetime import date\n",
    "import string\n",
    "import unicodedata\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rreplace(s, old, new, n_occurrence):\n",
    "    # Replace the last n_occurrence (n_occurrence = 1 is the last occurrence) of an expression in a string s\n",
    "    li = s.rsplit(old, n_occurrence)\n",
    "    return new.join(li)\n",
    "\n",
    "def str_format(stringg, sep = '_'):\n",
    "    \n",
    "    #Elimina simbolos de puntuación, u otros simbolos de un string\n",
    "    #Usar sep = \"_\" para nombre de columnas, usar sep = ' ' para contenido\n",
    "    \n",
    "    punctuation = list(string.punctuation)          \n",
    "    symbols = ['^','°', 'ª', os.linesep, '\\n']                     \n",
    "    new_string = unicodedata.normalize('NFKD', str(stringg)).encode('ascii', errors='ignore').decode('utf-8') # Elimina tildes \n",
    "\n",
    "    if sep == '_':\n",
    "        for i in range(len(punctuation)):\n",
    "            new_string = new_string.replace(punctuation[i], sep)   # Elimina simbolos de puntuación\n",
    "    else:\n",
    "        new_string = new_string.replace(';','.')\n",
    "    \n",
    "    for i in range(len(symbols)):\n",
    "        new_string = new_string.replace(symbols[i], '')           # Elimina otros simbolos\n",
    "    \n",
    "    if sep == '_':\n",
    "        new_string = new_string.replace(' ','_').lower()         # Elimina espacios \n",
    "    \n",
    "    while new_string[-1:] == sep:\n",
    "        new_string = rreplace(new_string,sep,'',1)           # Elimina los \"espacios\" (_) al final del string\n",
    "    \n",
    "    return new_string\n",
    "\n",
    "\n",
    "def read_txt(path, header_int, sep = '|', encoding = 'latin1'):\n",
    "# Lee los archivos txt del path (correspondientes a la fecha de descarga), y crea diccionario con respectivos dataframes\n",
    "    all_files = pd.Series(glob.glob(path + \"/*.txt\"))\n",
    "    fecha_str = date.today().strftime(\"%Y%m\")\n",
    "    files = all_files[all_files.astype(str).str.contains(fecha_str)].tolist()\n",
    "    d = {}\n",
    "    \n",
    "    for i in range(0,len(files)):\n",
    "        file_path = files[i]\n",
    "        index_from = file_path.rfind(\"\\\\\") + 1\n",
    "        file_name = str_format(file_path[index_from:-4])\n",
    "        \n",
    "        if file_name[:8].isdigit():\n",
    "            file_name = file_name[9:]\n",
    "        \n",
    "        d[str(file_name)] = pd.read_csv(file_path,header=header_int, sep=sep, encoding=encoding, dtype=str)\n",
    "    return d\n",
    "\n",
    "def clean_columns(dict, del_from, col=0):\n",
    "    for keys in dict:\n",
    "        # Elimina la primera y última columna \n",
    "        dict[keys] = dict[keys].drop(columns=dict[keys].columns[0]).\\\n",
    "        drop(columns = dict[keys].columns[-1]).dropna(how = 'all').reset_index(drop = True)\n",
    "        del_from_index = dict[keys].index[dict[keys][dict[keys].columns[col]].str.contains(del_from)].tolist()[0]\n",
    "        \n",
    "        #Elimina filas al final de txt que presentan el resumen del libro de compras/ventas\n",
    "        dict[keys] = dict[keys].iloc[0:del_from_index,:]\n",
    "    return dict\n",
    "\n",
    "def save_as_csv(dict, path, suffixes='', sep=';', encoding = 'latin1', index = False):\n",
    "    \n",
    "    for keys in dict:\n",
    "        dict[keys].to_csv(path + '\\\\' + dt.now().strftime('%Y%m%d') + str(keys) + suffixes + '.csv', sep=sep, index=index)\n",
    "        \n",
    "def read_xlsx(path, header_int, sheet_name_str=0):\n",
    "# Lee los archivos xlsx del path (correspondientes a la fecha de descarga), y crea diccionario con respectivos dataframes\n",
    "    all_files = pd.Series(glob.glob(path + \"/*.xlsx\"))\n",
    "    fecha_str = date.today().strftime(\"%Y%m\")\n",
    "    files = all_files[all_files.astype(str).str.contains(fecha_str)].tolist()\n",
    "    d = {}\n",
    "    \n",
    "    for i in range(0,len(files)):\n",
    "        file_path = files[i]\n",
    "        index_from = file_path.rfind(\"\\\\\") + 1\n",
    "        file_name = str_format(file_path[index_from:-4])\n",
    "        \n",
    "        if file_name[:8].isdigit():\n",
    "            file_name = file_name[9:]\n",
    "        \n",
    "        d[str(file_name)] = pd.read_excel(file_path, header=header_int, sheet_name=sheet_name_str, dtype=str)\n",
    "    return d\n",
    "\n",
    "def col_names_format(dict):\n",
    "    \n",
    "    for keys in dict:\n",
    "        df_col = dict[keys].columns\n",
    "        col_list = []\n",
    "        for col in df_col:\n",
    "            col_list.append(str_format(col))\n",
    "        dict[keys].columns = col_list\n",
    "    \n",
    "    return dict\n",
    "\n",
    "def schema_cols(dict, col_names, empty_col_value = np.nan):\n",
    "    for keys in dict:\n",
    "        for col in col_names:\n",
    "            if col not in dict[keys].columns:\n",
    "                dict[keys][col] = empty_col_value\n",
    "        dict[keys] = dict[keys][col_names]\n",
    "    return dict\n",
    "\n",
    "def replace_unnamed_cols(dict):\n",
    "    columns = []\n",
    "    for keys in dict:\n",
    "        for col in dict[keys].columns:\n",
    "            if 'Unnamed' in str(col):\n",
    "                col = ''\n",
    "            columns.append(col)\n",
    "    dict[keys].columns = columns\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r'C:/projects/data_lake/data/input/current/nomina_macroprocesos'\n",
    "output_path = r'C:/projects/data_lake/data/output/current/nomina_macroprocesos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar limpieza\n",
    "### Leer archivos y guardar en diccionario dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = read_xlsx(input_path,1,\"Proceso - MRC (SP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar formato de nombre de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = col_names_format(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190102_mapa_de_proceso_achs Index(['id', 'n1', 'categoria', 'n2', 'macroproceso', 'n3', 'proceso',\n",
      "       'prioridad_2017', 'prioridad_2018', 'linea_de_negocio',\n",
      "       'gerencia_responsable', 'gerencia___subgerencia_responsable',\n",
      "       'fecha_de_ultima_actualizacion', 'ano', 'numero_de_actualizacion',\n",
      "       'proyecto_de_mejora', 'mrcvigente', 'nombre_mrc', 'act_2017',\n",
      "       'fecha_ultima_actualizacion_mrc', 'pendiente_actualizacion',\n",
      "       'fecha_proxima_actualizacion', 'grupo', '1_era_reunion', 'estado',\n",
      "       '2da_reunion', 'estado__1', 'observacion', '3era_reunion', 'estado__2',\n",
      "       'observacion__1', 'estado', 'estado_mrc', '1era_reunion_mrc',\n",
      "       'estado_mrc_1', '2da_reunion_mrc', 'observacion', 'dueno_macroproceso',\n",
      "       'dueno_proceso', 'lider_proceso', 'gestor_de_proceso', 'cod_per_dm',\n",
      "       'cod_per_dp', 'cod_per_lp', 'cod_per_gp', 'vigente_dm', 'vigente_dp',\n",
      "       'vigente_lp', 'vigente_gp', 'validacion_uo_dp', 'validacion_uo_lp',\n",
      "       'validacion_uo_gp', '', 'estado__3', 'observaciones', 'fecha_de_inicio',\n",
      "       'fecha_de_envio_a_gs', 'fecha_de_firma__primero_que_firmo',\n",
      "       'dias_totales', '1sem_2018', '2sem_2018', '1sem_2019', '2sem_2019',\n",
      "       '1sem_2020', '2sem_2020', '1sem_2021', 'observaciones_1', 'clave',\n",
      "       'procesoshito_1', 'procesoshito_2', 'procesoshito_3', 'mrchito_1',\n",
      "       'mrchito_2', 'mrchito_3', 'procesoshito_1_1', 'procesoshito_2_1',\n",
      "       'procesoshito_3_1', 'mrchito_1_1', 'mrchito_2_1', 'mrchito_3_1',\n",
      "       'firma_divisional', 'tiene_indicadores', 'observacion_estado',\n",
      "       'procesoshito_1_2', 'procesoshito_2_2', 'procesoshito_3_2',\n",
      "       'mrchito_1_2', 'mrchito_2_2', 'mrchito_3_2', 'situacion_procesos', '',\n",
      "       'estado_proceso', 'situacion_mrc', '', 'estado_mrc_2', '0'],\n",
      "      dtype='object')\n",
      "20200109_mapa_de_proceso_achs Index(['id', 'n1', 'categoria', 'n2', 'macroproceso', 'n3', 'proceso',\n",
      "       'prioridad_2017', 'prioridad_2018', 'linea_de_negocio',\n",
      "       'fecha_de_ultima_actualizacion', 'ano', 'numero_de_actualizacion',\n",
      "       'tiene_indicadores', 'obj_coso', 'nivel_de_madurez', 'mrcvigente',\n",
      "       'nombre_mrc', 'fecha_ultima_actualizacion_mrc',\n",
      "       'fecha_proxima_actualizacion', 'tiene_pco',\n",
      "       'fecha_de_actualizacion_pco', 'cuenta_con_servicios_externalizados',\n",
      "       'dueno_macroproceso', 'dueno_proceso', 'lider_proceso',\n",
      "       'gestor_de_proceso', 'cod_per_dm', 'cod_per_dp', 'cod_per_lp',\n",
      "       'cod_per_gp', 'vigente_dm', 'vigente_dp', 'vigente_lp', 'vigente_gp',\n",
      "       'validacion_uo_dp', 'validacion_uo_lp', 'validacion_uo_gp', '1sem_2018',\n",
      "       '2sem_2018', '1sem_2019', '2sem_2019', '1sem_2020', '2sem_2020',\n",
      "       '1sem_2021', 'gr', '0', '0_1', '0_2', '0_3', '0_4', '0_5', '0_6', '0_7',\n",
      "       '0_8', '0_9', '0_10', '0_11', '0_12', '0_13', '0_14', '0_15', '0_16',\n",
      "       '0_17', '0_18', '0_19', '0_20', '0_21', '0_22', '0_23', '0_24', '0_25',\n",
      "       '0_26', '0_27', '0_28', '0_29', '0_30', '0_31', '0_32'],\n",
      "      dtype='object')\n",
      "20210118_nomina_responsables_procesos___mrc Index(['id', 'categoria', 'macroproceso', 'proceso', 'prioridad2018',\n",
      "       'fecha_de_ultima_actualizacion', 'mrc_vigente', 'nombre_mrc',\n",
      "       'fecha_ultima_actualizacion_mrc', 'fecha_de_actualizacionpco',\n",
      "       'dueno_macroproceso', 'dueno_proceso', 'lider_proceso',\n",
      "       'gestor_de_proceso'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for key in dict:\n",
    "    print(key,dict[key].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecer columnas que serán parte del esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['id', 'categoria', 'macroproceso', 'proceso', 'prioridad2018', 'prioridad_2017', 'prioridad_2018',\n",
    "       'fecha_de_ultima_actualizacion', 'mrc_vigente','mrcvigente', 'nombre_mrc',\n",
    "       'fecha_ultima_actualizacion_mrc', 'fecha_de_actualizacionpco',\n",
    "       'dueno_macroproceso', 'dueno_proceso', 'lider_proceso',\n",
    "       'gestor_de_proceso']\n",
    "\n",
    "dict = schema_cols(dict, col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rellenar valores nulos con \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in dict:\n",
    "    dict[keys].fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar formato de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in dict:\n",
    "    dict[keys] = dict[keys].applymap(lambda x: str_format(x, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar en archivos csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_csv(dict, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
