{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "from datetime import date\n",
    "import string\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rreplace(s, old, new, n_occurrence):\n",
    "    # Replace the last n_occurrence (n_occurrence = 1 is the last occurrence) of an expression in a string s\n",
    "    li = s.rsplit(old, n_occurrence)\n",
    "    return new.join(li)\n",
    "\n",
    "def str_format(stringg):\n",
    "    \n",
    "    #Elimina simbolos de puntuación, u otros simbolos de un string\n",
    "    \n",
    "    punctuation = list(string.punctuation)          \n",
    "    symbols = ['^','°']                     \n",
    "    new_string = unicodedata.normalize('NFKD', stringg).encode('ascii', errors='ignore').decode('utf-8') # Elimina tildes \n",
    "\n",
    "    for i in range(len(punctuation)):\n",
    "        new_string = new_string.replace(punctuation[i],'_')   # Elimina simbolos de puntuación\n",
    "    \n",
    "    for i in range(len(symbols)):\n",
    "        new_string = new_string.replace(symbols[i],'')       # Elimina otros simbolos\n",
    "    \n",
    "    new_string = new_string.replace(' ','_').lower()         # Elimina espacios \n",
    "    \n",
    "    while new_string[-1] == '_':\n",
    "        new_string = rreplace(new_string,'_','',1)           # Elimina los \"espacios\" (_) al final del string\n",
    "    \n",
    "    return new_string\n",
    "\n",
    "\n",
    "def read_file(path, header_int, file_extension, sep = '|', encoding = 'latin1'):\n",
    "# Lee los archivos del path (correspondientes a la fecha de descarga), y crea diccionario con respectivos dataframes\n",
    "    all_files = pd.Series(glob.glob(path + \"/*.\" + file_extension))\n",
    "    fecha_str = date.today().strftime(\"%Y%m\")\n",
    "    files = all_files[all_files.astype(str).str.contains(fecha_str)].tolist()\n",
    "    d = {}\n",
    "    \n",
    "    for i in range(0,len(files)):\n",
    "        file_path = files[i]\n",
    "        index_from = file_path.rfind(\"\\\\\") + 1\n",
    "        file_name = str_format(file_path[index_from:-4])\n",
    "        \n",
    "        if file_name[:8].isdigit():\n",
    "            file_name = file_name[9:]\n",
    "        \n",
    "        d[str(file_name)+\"_csv\"] = pd.read_csv(file_path,header=header_int, sep=sep, encoding=encoding, dtype=str)\n",
    "    return d\n",
    "\n",
    "def clean_columns(dict, del_from, col=0):\n",
    "    for keys in dict:\n",
    "        # Elimina la primera y última columna \n",
    "        dict[keys] = dict[keys].drop(columns=dict[keys].columns[0]).\\\n",
    "        drop(columns = dict[keys].columns[-1]).dropna(how = 'all').reset_index(drop = True)\n",
    "        del_from_index = dict[keys].index[dict[keys][dict[keys].columns[col]].str.contains(del_from)].tolist()[0]\n",
    "        \n",
    "        #Elimina filas al final de txt que presentan el resumen del libro de compras/ventas\n",
    "        dict[keys] = dict[keys].iloc[0:del_from_index,:]\n",
    "    return dict\n",
    "\n",
    "def save_as_csv(dict, path, sep=';', encoding = 'latin1'):\n",
    "    \n",
    "    for keys in dict:\n",
    "        dict[keys].to_csv(path + '\\\\' + dt.now().strftime('%Y%m%d') + str(keys) + '.csv', sep=sep)\n",
    "        \n",
    "def read_xlsx(path, header_int, sheet_name_str, encoding = 'latin1'):\n",
    "# Lee los archivos xlsx del path (correspondientes a la fecha de descarga), y crea diccionario con respectivos dataframes\n",
    "    all_files = pd.Series(glob.glob(path + \"/*.xlsx\"))\n",
    "    fecha_str = date.today().strftime(\"%Y%m\")\n",
    "    files = all_files[all_files.astype(str).str.contains(fecha_str)].tolist()\n",
    "    d = {}\n",
    "    \n",
    "    for i in range(0,len(files)):\n",
    "        file_path = files[i]\n",
    "        index_from = file_path.rfind(\"\\\\\") + 1\n",
    "        file_name = str_format(file_path[index_from:-4])\n",
    "        \n",
    "        if file_name[:8].isdigit():\n",
    "            file_name = file_name[9:]\n",
    "        \n",
    "        d[str(file_name)+\"_csv\"] = pd.read_excel(file_path, header=header_int, sheet_name=sheet_name_str, encoding=encoding, dtype=str)\n",
    "    return d\n",
    "\n",
    "def col_names_format(dict):\n",
    "    \n",
    "    for keys in dict:\n",
    "        df_col = dict[keys].columns\n",
    "        col_list = []\n",
    "        for col in df_col:\n",
    "            col_list.append(str_format(col))\n",
    "        dict[keys].columns = col_list\n",
    "    \n",
    "    return dict\n",
    "\n",
    "def schema_cols(dict, col_names):\n",
    "    for keys in dict:\n",
    "        dict[keys] = dict[keys][col_names]\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar limpieza\n",
    "### Leer archivos y guardar en df\n",
    "#### Ley Chile (separados por \";\") Resolucion MINSAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_str = date.today().strftime(\"%Y%m%d\")\n",
    "input_path = r'C:/projects/datalake/data/input/current/cambios_regulatorios'\n",
    "\n",
    "file_name1 = today_str + '_Resolucion_MINSAL.csv'\n",
    "file_path1 = input_path + '\\\\' + file_name1\n",
    "\n",
    "resolucion_minsal = pd.read_csv(file_path1, sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ley Chile (separados por \";\") Leyes Min Trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name2 = today_str + '_Leyes_Min-Trabajo.csv'\n",
    "file_path2 = input_path + '\\\\' + file_name2\n",
    "\n",
    "leyes_min_trabajo = pd.read_csv(file_path2, sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dejar columnas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Tipo/Número\",\"Fecha de Publicación\",\"Título de la Norma\",\"Fecha fin Vigencia\",\"Url\"]\n",
    "resolucion_minsal = resolucion_minsal[cols]\n",
    "leyes_min_trabajo = leyes_min_trabajo[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar en archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r'C:/projects/datalake/data/output/current/cambios_regulatorios'\n",
    "resolucion_minsal.to_csv(output_path + '\\\\' + dt.now().strftime('%Y%m%d') + '_Resolucion_MINSAL.csv', sep='|')\n",
    "leyes_min_trabajo.to_csv(output_path + '\\\\' + dt.now().strftime('%Y%m%d') + '_Leyes_Min-Trabajo.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
